# http+tcp

1. [(建议收藏)TCP 协议灵魂之问，巩固你的网路底层基础](https://juejin.cn/post/6844904070889603085)

## TCP 特点

TCP 是一个面向连接的、可靠的、基于字节流的传输层协议。

而 UDP 是一个面向无连接的传输层协议。(就这么简单，其它 TCP 的特性也就没有了)。

1.  **面向连接**：三次握手建立连接，UDP 无。

2.  **可靠性**：失败重传。
3.  **面向字节流** ：UDP 的数据传输是基于数据报的，而 TCP 是基于字节流。数据报是传输的最小单位，每个报文有明确的边界，UDP 并不会将应用层给的数据进行分割，而是有多少直接传多少，对端也是以报文为单位接收。TCP 基于字节流传输，并没有报文边界，传多少，对端接收后取多少取决于主机和网络（流量控制和拥塞控制）。

## TCP 三次握手

在 TCP/IP 协议中，TCP 协议通过三次握手建立一个可靠的连接

![TCP](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1f2d8d08cf1f442780396375d9f58ae1~tplv-k3u1fbpfcp-watermark.awebp)

1. 第一次握手：客户端尝试连接服务器，向服务器发送 syn 包（同步序列编号 Synchronize Sequence Numbers），syn=j，客户端进入 SYN_SEND 状态等待服务器确认
2. 第二次握手：服务器接收客户端 syn 包并确认（ack=j+1），同时向客户端发送一个 SYN 包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态
3. 第三次握手：第三次握手：客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK(ack=k+1），此包发送完毕，客户端和服务器进入 ESTABLISHED 状态，完成三次握手

**总结为：**

1. 客户端通知服务端建立链接
2. 服务端收到并回复，客户端建立好连接
3. 客户端回复服务端的回复，服务端建立好连接

### 为什么不是两次握手

三次握手的目的是确认双方都有 **发送** 和 **接收** 的能力。如果是两次握手，那服务端在一接到客户端连接请求就直接建立了连接，如果客户端本身无法接收数据，那这样的连接就会浪费服务端资源，例如：客户端 SYN 包超时了导致重传一次建立好连接，在数据传输完毕连接关闭后，超时的 SYN 包到达服务端，服务端又建立连接，但这时客户端并没有数据发送，造成服务端资源浪费。

## TCP 四次挥手

![TCP](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/2/23/170723e5c0e05829~tplv-t2oaga2asx-watermark.awebp)

客户端要断开了，向服务器发送 `FIN` 报文，发送后客户端变成了 `FIN-WAIT-1` 状态。注意, 这时候客户端同时也变成了 `half-close`(半关闭)状态，即无法向服务端发送报文，只能接收。

服务端接收后向客户端确认，变成了 `CLOSED-WAIT` 状态。

客户端接收到了服务端的确认，变成了 `FIN-WAIT2` 状态。

随后，服务端向客户端发送 `FIN` ，自己进入 `LAST-ACK` 状态，

客户端收到服务端发来的 `FIN` 后，自己变成了 `TIME-WAIT` 状态，然后发送 `ACK` 给服务端。

注意了，这个时候，客户端需要等待足够长的时间，具体来说，是 2 个 `MSL` (Maximum Segment Lifetime，报文最大生存时间), 在这段时间内如果客户端没有收到服务端的重发请求，那么表示 `ACK` 成功到达，挥手结束，否则客户端重发 `ACK` 。

**总结为：**

1. 客户端通知服务端我要断开连接。此时客户端进入半关闭状态，即不会向服务端发生数据，只接收。
2. 服务端收到并回复。
3. 待服务端剩余数据传输完毕后，服务端通知客户端我要断开。
4. 客户端收到并回复。服务端收到后断开。
5. 2MSL 后客户端断开。

### 为什么等待 2MSL

因为客户端需要在服务端关闭后再关闭，如果客户端先关闭了，那服务端后续可能会发送新的数据，而客户端对应端口正好被新应用占据，则会造成数据混乱。

等待 2MSL 是保证服务端没有收到 ACK 而重传的 FIN 报文可以到达：

1. 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
2. 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

### 为什么不是三次挥手

因为服务端在接收到`FIN`, 往往不会立即返回`FIN`, 必须等到服务端所有的报文都发送完毕了，才能发`FIN`。因此先发一个`ACK`表示已经收到客户端的`FIN`，延迟一段时间才发`FIN`。这就造成了四次挥手。

## TCP 的流量控制

对于发送端和接收端而言，TCP 需要把发送的数据放到发送缓存区, 将接收的数据放到接收缓存区。

而流量控制索要做的事情，就是在通过接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。

流量控制依赖于滑动窗口，TCP 滑动窗口分为两种: 发送窗口和接收窗口。当接收端处理能力不够时，会通知发送端少发送数据。

## TCP 拥塞控制

流量控制用于处理端对端的数据处理情况，而拥塞控制用于处理网络环境的问题。

拥塞窗口（Congestion Window，cwnd）是指目前自己还能传输的数据量大小。

那么之前介绍了接收窗口的概念，两者有什么区别呢？

1. 接收窗口(rwnd)是接收端给的限制
2. 拥塞窗口(cwnd)是发送端的限制

```
发送窗口大小 = min(rwnd, cwnd)
```

### 慢启动

开始传输的一段时间，发送端每收到一个 ACK，拥塞窗口大小加 1，也就是说，每经过一个 RTT((Round-Trip Time，往返时延))，cwnd 翻倍，直到达到阈值。

### 拥塞避免

慢启动阶段一个 RTT 下来，cwnd 翻倍，达到阈值后，一个 RTT 下来， cwnd 只是增加 1。

### 快重传

比如：第 5 个包丢了，即使第 6、7 个包到达的接收端，接收端也一律返回第 4 个包的 ACK。当发送端收到 3 个重复的 ACK 时，意识到丢包了，于是马上进行重传，不用等到一个 RTO(超时重传时间) 的时间到了才重传。

### 快速恢复

发送端收到三次重复 ACK 之后，发现丢包，觉得现在的网络已经有些拥塞了，自己会进入快速恢复阶段。

发送端如下改变：

1. 拥塞阈值降低为 cwnd 的一半
2. cwnd 的大小变为拥塞阈值
3. cwnd 线性增加

## http 特点

-   HTTP 是无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
-   HTTP 是媒体独立的：这意味着，只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过 HTTP 发送。客户端以及服务器指定使用适合的 MIME-type 内容类型。
-   HTTP 是无状态：这里的状态是指通信过程的上下文信息，而每次 http 请求都是独立、无关的，默认不需要保留状态信息。

## http 缺点

1. 无状态
2. 明文传输
3. 队头堵塞

## http 状态码

1xx(临时响应)

100: 请求者应当继续提出请求。

101(切换协议) 请求者已要求服务器切换协议，服务器已确认并准备进行切换。

2xx(成功)

200：正确的请求返回正确的结果

201：表示资源被正确的创建。比如说，我们 POST 用户名、密码正确创建了一个用户就可以返回 201。

202：请求是正确的，但是结果正在处理中，这时候客户端可以通过轮询等机制继续请求。

3xx(已重定向)

300：请求成功，但结果有多种选择。

**301：请求成功，但是资源被永久转移。**
**302：请求成功，但是资源被临时转移。**

303：使用 GET 来访问新的地址来获取资源。

304：请求的资源并没有被修改过

4xx(请求错误)

**400：请求出现错误，比如请求头不对等。**

**401：没有提供认证信息。请求的时候没有带上 Token 等。**

402：为以后需要所保留的状态码。

**403：请求的资源不允许访问。就是说没有权限。**

404：请求的内容不存在。

5xx(服务器错误)

**500：服务器错误。**

501：请求还没有被实现。

## http 缓存

强缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。
协商缓存，让客户端与服务器之间能实现缓存文件是否更新的验证、提升缓存的复用率，将缓存信息中的 Etag 和 Last-Modified
通过请求发送给服务器，由服务器校验，返回 304 状态码时，浏览器直接使用缓存。

HTTP 缓存都是从第二次请求开始的：

第一次请求资源时，服务器返回资源，并在 response header 中回传资源的缓存策略；
第二次请求时，浏览器判断这些请求参数，击中强缓存就直接 200，否则就把请求参数加到 request header 头中传给服务器，看是否击中协商缓存，击中则返回 304，否则服务器会返回新的资源。

1. 强缓存

    - 强缓存命中则直接读取浏览器本地的资源，在 network 中显示的是 from memory 或者 from disk
    - **控制强制缓存的字段有：Cache-Control（http1.1）和 Expires（http1.0）**
    - Cache-control 是一个相对时间，用以表达自上次请求正确的资源之后的多少秒的时间段内缓存有效。
    - Expires 是一个绝对时间。用以表达在这个时间点之前发起请求可以直接从浏览器中读取数据，而无需发起请求
    - Cache-Control 的优先级比 Expires 的优先级高。前者的出现是为了解决 Expires 在浏览器时间被手动更改导致缓存判断错误的问题。
    - 如果同时存在则使用 Cache-control。

    Cache-control 字段常用的值：

    1. max-age：即最大有效时间。
    2. must-revalidate：如果超过了 max-age 的时间，浏览器必须向服务器发送请求，验证资源是否还有效。
    3. no-cache：不使用强缓存，需要与服务器验证缓存是否新鲜。
    4. no-store: 真正意义上的“不要缓存”。所有内容都不走缓存，包括强制和对比。
    5. public：所有的内容都可以被缓存 (包括客户端和代理服务器， 如 CDN)
    6. private：所有的内容只有客户端才可以缓存，代理服务器不能缓存。默认值。

    no-cache 和 no-store 的区别：

    1. no-cache：是把资源进行了本地缓存，在浏览器使用缓存之前，会使用 last-Modified 和 Etag 往返浏览器进行对比，判断时间和唯一标识符和服务器的是否一致，一致的话 304 使用缓存，不一致的话请求服务器。
    2. no-store：才是真正的完完全全的禁止本地缓存。

2. 协商缓存
    - 协商缓存的状态码由服务器决策返回 200 或者 304
    - 当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了 If-Modified-Since 或者 If-None-Match 的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 Last-Modified 或者 ETag 属 性。
    - 对比缓存在请求数上和没有缓存是一致的，但如果是 304 的话，返回的仅仅是一个状态码而已，并没有实际的文件内容，因此 在响应体体积上的节省是它的优化点。
    - **协商缓存有 2 组字段(不是两个)，控制协商缓存的字段有：Last-Modified/If-Modified-since（http1.0）和 Etag/If-None-match（http1.1）**
    - Last-Modified/If-Modified-since 表示的是服务器的资源最后一次修改的时间；
    - Etag/If-None-match 表示的是服务器资源的唯一标识，只要资源变化，Etag 就会重新生成。
    - Etag/If-None-match 的优先级比 Last-Modified/If-Modified-since 高。

[说一下 Http 缓存策略，有什么区别，分别解决了什么问题](https://github.com/lgwebdream/FE-Interview/issues/14)

## get、post 的区别

-   从**缓存**的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
-   从**编码**的角度，GET 只能进行 URL 编码，只能接收 ASCII 字符，而 POST 没有限制。
-   从**参数**的角度，GET 一般放在 URL 中，因此不安全，POST 放在请求体中，更适合传输敏感信息。
-   从**幂等性**的角度，`GET`是**幂等**的，而`POST`不是。(`幂等`表示执行相同的操作，结果也是相同的)
-   从**TCP**的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分。(**火狐**浏览器除外，它的 POST 请求只发一个 TCP 包)

## http1.0, 2.0, 3.0

### HTTP1.x 的缺点

1. 队头阻塞。
   Chrome 有个机制，对于同一个域名，默认允许同时建立 6 个 TCP 持久连接，使用持久连接时，虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。另外如果在同一个域名下同时有 10 个请求发生，那么其中 4 个请求会进入排队等待状态，直至进行中的请求完成。
2. 单向请求，只能由客户端发起。
3. 请求报文与响应报文首部信息冗余量大。
4. 明文传输

### HTTP2.0 特点

1. 二进制传输
   把原来的"Header+Body"的消息"打散"为数个小片的二进制"帧"(Frame),用"HEADERS"帧存放头数据、"DATA"帧存放实体数据。HTP/2 数据分帧后"Header+Body"的报文结构就完全消失了，协议看到的只是一个个的"碎片"。
2. 多路复用
   HTTP2.0 中，有两个概念非常重要：帧（frame）和流（stream）。
   帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流是多个帧组成的数据流。
   所谓多路复用，即在一个 TCP 连接中存在多个流，即可以同时发送多个请求，对端可以通过帧中的表示知道该帧属于哪个请求。在客户端，这些帧乱序发送，到对端后再根据每个帧首部的流标识符重新组装。通过该技术，可以避免 HTTP 旧版本的队头阻塞问题，极大提高传输性能。
3. Header 压缩
4. 服务器 push
5. 更安全

缺点：

1. TCP 以及 TCP+TLS 建立连接的延时
2. TCP 的队头阻塞并没有彻底解决
   TCP 为了保证可靠传输，有个特别的“丢包重传”机制，丢失的包必须要等待重新传输确认，HTTP/2 出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该 TCP 连接中的所有请求（如下图）。而对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。

https://juejin.im/post/6844904152850497544#heading-60

### HTTP3.0

HTTP2.0 也是基于 TCP 协议的，tcp 协议在处理包时是有严格顺序的

当其中一个数据包遇到问题，TCP 连接需要等待这个包完成重传之后才能继续进行，虽然 HTTP2.0 通过多个 stream，使得逻辑上一个 tcp 连接上的并行内容，进行多路数据的传输，然而这中间没有关联的数据，一前一后，前面 stream2 的帧没有收到，后面 stream1 的帧也会因此堵塞。

HTTP3 基于 QUIC 协议， QUIC (Quick UDP Internet Connections), 快速 UDP 互联网连接。
QUIC 是基于 UDP 协议的。

QUIC 有自定义连接机制，自定义重传机制，解决了 TCP 的问题。

## HTTPS

简单来说，如果是对称加密，那在传输数据前，必然会传输一次密钥，那就可能被中间人拿到这个密钥。

如果是非对称加密，那也必须去传输一次公钥，客户端只持有公钥，服务端持有私钥（公钥加密私钥能解密，私钥加密公钥解密），服务端传输的数据只能是私钥加密，而公钥所有人都知道。非对称只能保证单端传输安全。

两者结合，服务端给予公钥给浏览器，浏览器生成一个密钥并用公钥加密，再将加密的密钥数传给服务端，服务端用私钥解密。这样两边都有这个密钥，用这个密钥对称加密。

这个密钥难以被中间人拿到，它只传输过一次，并且被公钥加密。

**总结如下**：在浏览器端通过随机数生成对称加密密钥，将这个对此加密密钥用非对称加密公钥加密后再传送给服务端，传输过程中即使被劫持由于没有非对称加密密钥也无法解密，最后双方都得到对称加密密钥。

具体如下：
https://juejin.im/post/6844904021308735502#heading-84

### 数字证书

尽管通过两者加密方式的结合，能够很好地实现加密传输，但实际上还是存在一些问题。黑客如果采用 DNS 劫持，将目标地址替换成黑客服务器的地址，然后黑客自己造一份公钥和私钥，照样能进行数据传输。而对于浏览器用户而言，他是不知道自己正在访问一个危险的服务器的。

HTTPS 在上述结合对称和非对称加密的基础上，又添加了数字证书认证的步骤。其目的就是让服务器证明自己的身份。

数字证书有两个作用:

1. 服务器向浏览器证明自己的身份。（用 CA 的公钥去解证书的签名，得到证书信息，在通过浏览器或者操作系统内置的合法 CA 列表去验证证书是否合法）
2. 把公钥传给浏览器。

只有 CA 机构颁发的数字证书才是安全有效的。

### 中间人攻击

中间人攻击(Man-in-the-MiddleAttack，简称“MITM 攻击”)是指攻击者与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方 直接对话，但事实上整个会话都被攻击者完全控制。

中间人攻击过程：

1. 客户端发送请求到服务端，请求被中间人截获。
2. 服务器向客户端发送公钥。
3. 中间人截获公钥，保留在自己手上。然后自己生成一个【伪 造的】公钥，发给客户端。
4. 客户端收到伪造的公钥后，生成加密 hash 值发给服务器。
5. 中间人获得加密 hash 值，用自己的私钥解密获得真秘钥。同时生成假的加密 hash 值，发给服务器。
6. 服务器用私钥解密获得假密钥。然后加密数据传输给客户端。


解决方法：同上通过 CA 数字证书，去验证服务端是否合法。

### SSL 具体过程

<!-- todo -->

## websocket

1. tcp 三次握手
2. 发了一个 http 请求，用于协议升级
3. 服务器如果支持 websocket 协议的话，会返回 101 状态码表示同意协议升级，
4. 完成了协议的升级，后续的数据通信，就是基于 tcp 连接之上，使用 websocket 协议封装的数据包。

## DNS 查询

例如解析`www.google.com`： . -> .com -> google.com. -> www.google.com

**递归查询：**

1. 首先在**本地域名服务器**中查询 IP 地址，如果没有找到的情况下
2. **本地域名服务器**会向**根域名服务器**发送一个请求，
3. **本地域名服务器**会向 **com 顶级域名服务器**发送一个请求，
4. 最后**本地域名**再向 **google.com 域名服务器** 发送请求查询

**迭代查询：**

递归的特点是本地域名服务器代理客户端查询其他域名服务器，而迭代查询相反，全是有客户端去查询各个域名服务器。

DNS 缓存：浏览器，系统，路由器，各域名服务器。

https://segmentfault.com/a/1190000006879700#comment-area
